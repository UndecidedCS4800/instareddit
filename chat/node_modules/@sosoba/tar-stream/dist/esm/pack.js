import { deepStrictEqual, ok } from 'node:assert';
import { once } from 'node:events';
import { Transform, Writable } from 'node:stream';
import { callbackify } from 'node:util';
import { encodeTarHeader, encodePaxData, splitName, TAR_BLOCK_SIZE, TYPE_FLAG_PAX, TYPE_FLAG_REGTYPE } from './headers';
export class Pack {
    static TAR_END_BLOCKS_COUNT = 2;
    paxCounter = 0;
    transform = new Transform({
        transform: (chunk, encoding, callback) => {
            deepStrictEqual(encoding, 'buffer');
            callback(null, chunk);
        },
    });
    get outputStream() {
        return this.transform;
    }
    async addFile(fileOptions, content) {
        let size = fileOptions.size;
        if (content) {
            if (size !== undefined && size !== content.length) {
                throw new Error(`Declared lenght ${size} but ${content.length} given`);
            }
            size = content.length;
        }
        if (size === undefined) {
            throw new Error('Missing size');
        }
        let prefix;
        if (Buffer.byteLength(fileOptions.name, 'utf8') !== fileOptions.name.length) {
            fileOptions.name = await this.addPaxFile(fileOptions);
        }
        else {
            const nameAndPrefix = splitName(fileOptions.name);
            if (nameAndPrefix) {
                fileOptions.name = nameAndPrefix.name;
                prefix = nameAndPrefix.prefix;
            }
            else {
                fileOptions.name = await this.addPaxFile(fileOptions);
            }
        }
        const writable = await this.addEntry({
            ...fileOptions,
            prefix,
            size,
            devmajor: 0,
            devminor: 0,
            typeflag: TYPE_FLAG_REGTYPE,
        });
        if (!content) {
            return writable;
        }
        writable.end(content);
        await once(writable, 'finish');
    }
    async end() {
        await this.writeBuffer(Buffer.alloc(TAR_BLOCK_SIZE * Pack.TAR_END_BLOCKS_COUNT));
        this.transform.end();
        await once(this.transform, 'finish');
    }
    async addPaxFile(fileOptions) {
        const paxContent = encodePaxData({
            path: fileOptions.name,
        });
        const paxWritable = await this.addEntry({
            ...fileOptions,
            name: `PaxHeader/${this.paxCounter++}`,
            size: paxContent.length,
            typeflag: TYPE_FLAG_PAX,
            devmajor: 0,
            devminor: 0
        });
        ok(paxWritable);
        paxWritable.end(paxContent);
        await once(paxWritable, 'finish');
        return `PaxHeader/${this.paxCounter++}`;
    }
    async addEntry(header) {
        await this.writeBuffer(encodeTarHeader(header));
        const tail = TAR_BLOCK_SIZE - header.size % TAR_BLOCK_SIZE;
        return new Writable({
            write: (chunk, encoding, callback) => {
                if (encoding !== 'buffer') {
                    throw new Error(`This stream does not support string [${encoding}] encoding`);
                }
                this.writeBuffer(chunk).then(() => {
                    callback();
                }, (e) => {
                    callback(e);
                });
            },
            final: callbackify(async () => {
                if (tail !== TAR_BLOCK_SIZE) {
                    await this.writeBuffer(Buffer.alloc(tail));
                }
            }),
        });
    }
    async writeBuffer(buffer) {
        if (this.transform.destroyed) {
            throw new Error('Stream is already destroyed');
        }
        if (!this.transform.writable) {
            throw new Error('Stream is not writable');
        }
        if (!this.transform.write(buffer)) {
            await once(this.transform, 'drain');
        }
    }
}
//# sourceMappingURL=pack.js.map